{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a5b234",
   "metadata": {},
   "source": [
    "### Human Shade Detection\n",
    "\n",
    "created by ruyiyang in 2024/10\n",
    "\n",
    "cleaned in 2025/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d65368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from ultralytics import YOLO, solutions\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8618912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Workfolder\\Computer-vision\\shade-human\\data\\raw-video\\Kabukicho\\Kabukicho_240825_truncated.mp4\n",
      "Kabukicho_240825_truncated\n"
     ]
    }
   ],
   "source": [
    "video_path = r'E:\\Workfolder\\Computer-vision\\shade-human\\data\\raw-video\\Kabukicho\\Kabukicho_240825_truncated.mp4'\n",
    "file_name = os.path.splitext(os.path.basename(video_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fdd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video preprocessing\n",
    "\n",
    "# option 1 Adjust the frame rate to 5 FPS, and the total duration remains unchanged\n",
    "# !ffmpeg -i \"data/raw video/Kabukicho_240825_truncated.mp4\" -r 5 \"data/raw video/Kabukicho_240825_truncated_5fps.mp4\"\n",
    "\n",
    "\n",
    "# # option 2 function: subsample/time laspe video\n",
    "# def subsample_video(input_path, output_path, time_lapse_interval):\n",
    "#     cap = cv2.VideoCapture(input_path)\n",
    "#     if not cap.isOpened():\n",
    "#         print(\"Error: Couldn't open video file.\")\n",
    "#         return\n",
    "\n",
    "#     frame_count = 0\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#     out = cv2.VideoWriter(output_path, codec, fps, (width, height))\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Collect one frame out of every xx frames\n",
    "#         if frame_count % time_lapse_interval == 0:\n",
    "#             out.write(frame)\n",
    "\n",
    "#         frame_count += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     time_lapse_interval = 5 # change here\n",
    "#     input_file = video_path \n",
    "#     output_file = f\"data/raw video/time_lapse/{file_name}_timelapsed{time_lapse_interval}.mp4\"  # Replace with desired output video file path\n",
    "#     subsample_video(input_file, output_file, time_lapse_interval)\n",
    "#     print(f\"saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'E:\\Workfolder\\Computer-vision\\shade-human\\data\\raw-video\\Kabukicho\\Kabukicho_240825_truncated.mp4'\n",
    "file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "print(video_path)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddfbd21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of frames in the video：631\n",
      "Video frame rate：59.999998098256796\n"
     ]
    }
   ],
   "source": [
    "# number of frames in the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the file name\n",
    "file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "# Get the total number of frames of the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(f\"The total number of frames in the video：{total_frames}\\nVideo frame rate：{original_fps}\")\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function: detect people whether in the shadow from the video\n",
    "change the parameters\n",
    "'''\n",
    "\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "output_video_path = \"output/human-and-shade-tracking_{}.avi\".format(file_name)\n",
    "csv_file = 'output/detections_{}.csv'.format(file_name)\n",
    "\n",
    "# 初始化 Roboflow 客户端用于阴影检测\n",
    "CLIENT = InferenceHTTPClient(api_url=\"https://detect.roboflow.com\", api_key=\"GMoYRhBgraVdGZ6B3fFz\")\n",
    "\n",
    "# 加载 YOLO 模型用于人物检测\n",
    "model_person = YOLO('yolo11l.pt')  \n",
    "\n",
    "# 打开视频文件\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))\n",
    "\n",
    "# 初始化 CSV 文件\n",
    "csv_headers = ['frame', 'person_id', 'bottom_mid_x', 'bottom_mid_y', 'in_shadow']\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(csv_headers)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "# 统计信息变量\n",
    "total_people = 0\n",
    "people_in_shadow = 0\n",
    "people_outside_shadow = 0\n",
    "\n",
    "# 创建窗口并设置窗口大小\n",
    "# cv2.namedWindow(\"instance-segmentation-object-tracking\", cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow(\"instance-segmentation-object-tracking\", 800, 600)\n",
    "\n",
    "# 开始处理每一帧\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Perform people count detection every frame, change here\n",
    "    if frame_count % 1 == 0:\n",
    "        # 获取当前帧的阴影 boundary\n",
    "        shadow_result = CLIENT.infer(frame, model_id=\"shade-detection/1\")\n",
    "        boundaries = []\n",
    "\n",
    "        # 单张图片inference的数据结构\n",
    "        if 'predictions' in shadow_result:  # 单张图像的结构\n",
    "            predictions = shadow_result['predictions']\n",
    "            for prediction in predictions:\n",
    "                points = prediction.get(\"points\", [])\n",
    "                if points:\n",
    "                    boundary = [(int(point['x']), int(point['y'])) for point in points]\n",
    "                    boundaries.append(boundary)  # 将阴影区域的点坐标添加到 boundaries 列表中\n",
    "\n",
    "        annotator = Annotator(frame, line_width=2)\n",
    "        \n",
    "        # 重置统计变量\n",
    "        people_in_shadow = 0\n",
    "        people_outside_shadow = 0\n",
    "        total_people = 0\n",
    "        detections = []  # 初始化为空列表，以便在每次检测时更新\n",
    "\n",
    "        # 绘制阴影多边形\n",
    "        for boundary in boundaries:\n",
    "            # 使用 cv2.polylines 画出多边形阴影区域\n",
    "            boundary_points = np.array(boundary, np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(frame, [boundary_points], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "        # 检测人\n",
    "        # person_results = model_person(frame, classes=[0], conf=0.05, show=False)  # 0是人的类别ID，关闭自动显示窗口\n",
    "        person_results = model_person.track(frame, persist=True, classes=[0], conf=0.05, show=False) \n",
    "        \n",
    "        if person_results and len(person_results) > 0:\n",
    "            boxes = person_results[0].boxes\n",
    "\n",
    "            if boxes and len(boxes) > 0:\n",
    "                # 提取 bounding boxes\n",
    "                xyxy = boxes.xyxy.cpu().numpy()  # 以 xyxy 格式获取盒子\n",
    "                track_ids = np.arange(len(xyxy))  # 为每个框生成唯一ID\n",
    "\n",
    "                for i, (x1, y1, x2, y2) in enumerate(xyxy):\n",
    "                    bottom_mid_x = (x1 + x2) / 2  # 底边中点的 X 坐标\n",
    "                    bottom_mid_y = y2  # 底边的 Y 坐标\n",
    "                    in_shadow = False\n",
    "\n",
    "                    # 检查是否在阴影中\n",
    "                    for boundary in boundaries:\n",
    "                        if cv2.pointPolygonTest(np.array(boundary, np.int32), (int(bottom_mid_x), int(bottom_mid_y)), False) >= 0:\n",
    "                            in_shadow = True\n",
    "                            people_in_shadow += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        people_outside_shadow += 1\n",
    "\n",
    "                    # 记录检测结果\n",
    "                    detections.append([frame_count, track_ids[i], bottom_mid_x, bottom_mid_y, in_shadow])\n",
    "                    total_people += 1\n",
    "\n",
    "                    # 显示检测框、文本和底边中点的圆点\n",
    "                    color = colors(int(track_ids[i]), True)\n",
    "                    txt_color = annotator.get_txt_color(color)\n",
    "                    label = f\"ID {track_ids[i]} {'in shadow' if in_shadow else 'out shadow'}\"\n",
    "                    annotator.box_label([x1, y1, x2, y2], label=label, color=color, txt_color=txt_color)\n",
    "                    cv2.circle(frame, (int(bottom_mid_x), int(bottom_mid_y)), 5, (0, 0, 255), -1)  # 绘制底边中点\n",
    "\n",
    "        # 将结果写入 CSV\n",
    "        with open(csv_file, 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(detections)\n",
    "\n",
    "    # 将统计结果显示在帧上\n",
    "    text = f\"Frame {frame_count}: Total: {total_people}, In Shadow: {people_in_shadow}, Outside Shadow: {people_outside_shadow}\"\n",
    "    cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # 写入视频帧\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"instance-segmentation-object-tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processing complete. Results saved in {output_video_path} and {csv_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472b5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metabolicwalking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
